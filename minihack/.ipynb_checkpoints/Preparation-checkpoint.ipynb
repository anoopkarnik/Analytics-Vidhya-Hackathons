{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all the libraries\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import cross_validation,metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defined functions for running algortihms\n",
    "def modelfit(alg,dtrain,dtest,predictiors, performCV = True, printFeatureImportance=True, cv_folds = 5):\n",
    "    alg.fit(dtrain[predictors],dtrain['Is_Shortlisted'])\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg,dtrain[predictors],dtrain['Is_Shortlisted'], cv = cv_folds, scoring = 'roc_auc')\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\"%(np.mean(cv_score),np.std(cv_score),np.min(cv_score),\n",
    "                                                                        np.max(cv_score))\n",
    "    print \"Accuracy - %.4g\" % metrics.accuracy_score(dtrain['Is_Shortlisted'],dtrain_predictions)\n",
    "    print \"AUC Score - %f\" % metrics.roc_auc_score(dtrain['Is_Shortlisted'],dtrain_predprob)\n",
    "    \n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_,predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind = 'bar', title = 'Feature Importance')\n",
    "        plt.ylabel('Feature Importance Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all the datasets\n",
    "data = pd.read_csv(\"C:/Users/user/Documents/data3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exploratory analysis\n",
    "data.dtypes\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the null values in the dataset\n",
    "data.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replacing Null Values\n",
    "data['Preferred_location'] = data['Preferred_location'].apply(lambda x : 'NS' if pd.isnull(x) else x)\n",
    "datais['Stipend1']= datais['Stipend1'].fillna(0)\n",
    "student_exp['Experience_Type'] = student_exp['Experience_Type'].fillna('NE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Joining and Merging \n",
    "datai = pd.merge(data,internship,how = 'left', on = 'Internship_ID')\n",
    "train['data'] ='train'\n",
    "test['data'] = 'test'\n",
    "combi = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some other preprocessing tasks\n",
    "datais_dates = datais[['Student_ID','Earliest_Start_Date']]\n",
    "student_exp = student_exp[student_exp['Start.Date'].notnull()]\n",
    "student_exp['Profile'] = student_exp[['Student_ID','Profile']].groupby(['Student_ID'])['Profile'].transform(lambda x: ','.join(x))\n",
    "student_exp['Experience_Type'] = student_exp[['Student_ID','Experience_Type']].groupby(['Student_ID'])['Experience_Type'].transform(lambda x: ','.join(x))\n",
    "student_exp_unique = student_exp[['Student_ID','Experience_Type','Profile']].drop_duplicates()\n",
    "dataise['degree_base'] = 'empty'\n",
    "for i in range(len(dataise)):\n",
    "    dataise['Degree'][i] = str(dataise['Degree'][i])\n",
    "    dataise['degree_base'][i] = np.where(re.search(r'^(u|b|B|U)',dataise['Degree'][i]),'UG',np.where(\n",
    "            re.search(r'^(m|p|M|P)',dataise['Degree'][i]),'PG','Others'))\n",
    "dataise['Stipend_avg_match'] = np.where(dataise['avg_stipend'] >= dataise['student_stipend'],'Yes','No')\n",
    "dataise['student_stipend'] = np.where(dataise['Expected_Stipend']=='No Expectations',0 ,np.where(dataise['Expected_Stipend']==\n",
    "                                                                                     '2-5K',2000,np.where(dataise['Expected_Stipend']==\n",
    "                                                                                                         '5-10K',5000,10000)))\n",
    "dataise['avg_stipend'] = np.where(dataise['Stipend2'].isnull(),dataise['Stipend1'],(dataise['Stipend1']+dataise['Stipend2'])/2)\n",
    "def common_elements(list1, list2):\n",
    "    a =  [element for element in list1 if element in list2]\n",
    "    return len(a)\n",
    "dataise['skill_common2'] = 0\n",
    "for i in range(len(dataise)):\n",
    "    dataise['profile_common'][i] = common_elements(dataise['Internship_Profile'][i],dataise['Profile'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some other preprocessing tasks 2 \n",
    "dataise['degree_base'] = ''\n",
    "for i in range(len(dataise)):\n",
    "    dataise['Degree'][i] = str(dataise['Degree'][i])\n",
    "    dataise['degree_base'][i] = np.where(re.search(r'^(u|b|B|U)',dataise['Degree'][i]),'UG',np.where(\n",
    "            re.search(r'^(m|p|M|P)',dataise['Degree'][i]),'PG','Others'))\n",
    "def str_replace(s):\n",
    "    s= str(s)\n",
    "    s= re.sub(r'^(b|B|U|u).*$',\"UG\",s)\n",
    "    s= re.sub(r'^(p|P|M|m).*$',\"PG\",s)\n",
    "    s= np.where(s==\"UG\",\"UG\",np.where(s==\"PG\",\"PG\",\"other\"))\n",
    "    return s    \n",
    "dataise['degree_base'] = dataise['Degree'].apply(lambda x : str_replace(x)) \n",
    "def common_elements(list1, list2):\n",
    "    if isinstance(list1, basestring):\n",
    "        if isinstance(list2,basestring):\n",
    "            if list1==list2:\n",
    "                a=['Match']\n",
    "            else:\n",
    "                a=[]\n",
    "        else:\n",
    "            for word in list2:\n",
    "                if list1==word:\n",
    "                    a=['Match']\n",
    "                else:\n",
    "                    a=[]\n",
    "    else:\n",
    "        a =  [element for element in list1 if element in list2]\n",
    "    return len(a)\n",
    "dataise['profile_common'] = dataise.apply(lamda x: common_elements(x['Internship_Profile'],x['Profile']),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text Preprocessing\n",
    "dataise['skill_compress_str'] = [nltk.word_tokenize(sent) for sent in dataise['skill_compress_str']]\n",
    "dataise['Profile'] = [nltk.word_tokenize(sent.decode('utf8', 'ignore')) for sent in dataise['Profile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Date Preprocessing\n",
    "student_exp['Start.Date'] = pd.to_datetime(student_exp['Start.Date'], format=\"%m/%d/%Y\")\n",
    "from datetime import datetime\n",
    "date_format = \"%m/%d/%Y\"\n",
    "student_exp['Start.Date'] datetime.strptime('8/18/2008', date_format)\n",
    "b = datetime.strptime('9/26/2008', date_format)\n",
    "student_exp['exp_days'] = np.where(student_exp['Start.Date'].isnull(),0, np.where(student_exp['End.Date'].isnull(),-1,\n",
    "                                                                                 student_exp['End.Date']-student_exp['Start.Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop fields\n",
    "dataise.drop('Performance_PG',axis=1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Encoder\n",
    "data_new = dataise[x for x in dataise.columns ]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "var_to_encod = ['Expected_Stipend','Preferred_location','Is_Part_Time','Internship_Profile','Internship_Type','Internship_Location','Internship_category',\n",
    "                 'Stipend_Type','skill_compress_str','Institute_Category','Degree','Stream','Year_of_graduation',\n",
    "                 'PG_scale','UG_Scale','Experience_Type','location_match','Stipend_low_match','Stipend_avg_match','Current_year','degree_base']\n",
    "for col in var_to_encode:\n",
    "    data_new[col] = le.fit_transform(data_new[col])\n",
    "data_new = pd.get_dummies(data_new, columns=var_to_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature importance and Error\n",
    "train = data_new.loc[data_new['source'] == 'train']\n",
    "test = data_new.loc[data_new['source']=='test']\n",
    "train.drop('source',axis=1,inplace=True)\n",
    "test.drop('Is_Shortlisted',axis=1,inplace=True)\n",
    "predictors = [x for x in train.columns if x not in ['Internship_ID','Student_ID','Is_Shortlisted']]\n",
    "gbm = GradientBoostingClassifier(random_state=143)\n",
    "modelfit(gbm,train,test,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid Search GBM\n",
    "param_test1 = {'n_estimators': range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate = 0.1, min_samples_split =500,min_samples_leaf = 50,\n",
    "                                                              max_depth = 8,max_features ='sqrt',subsample=0.8,random_state =10),\n",
    "                      param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False,cv=5)\n",
    "gsearch1.fit(train[predictors],train['Is_Shortlisted'])\n",
    "gsearch1.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train['Is_Shortlisted'])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "param_test3 = {'min_samples_split':range(1000,2100,200), 'min_samples_leaf':range(30,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train['Is_Shortlisted'])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "param_test4 = {'max_features':range(7,20,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9, min_samples_split=1200, min_samples_leaf=60, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train['Is_Shortlisted'])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_\n",
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,min_samples_split=1200, min_samples_leaf=60, subsample=0.8, random_state=10,max_features=7),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train['Is_Shortlisted']\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=120,max_depth=9, min_samples_split=1200,min_samples_leaf=60, subsample=0.85, random_state=10, max_features=7)\n",
    "test['Is_Shortlisted'] = gbm.predict(test[predictors])\n",
    "result = test[['Internship_ID','Student_ID','Is_Shortlisted']]\n",
    "result.to_csv(\"result4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final predictitest['Is_Shortlisted'] = gbm.predict(test[predictors])\n",
    "result = test[['Internship_ID','Student_ID','Is_Shortlisted']]\n",
    "result.to_csv(\"result.csv\")on and submission \n",
    "test['Is_Shortlisted'] = gbm.predict(test[predictors])\n",
    "result = test[['Internship_ID','Student_ID','Is_Shortlisted']]\n",
    "result.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#other models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train[predictors],train['Is_Shortlisted'])\n",
    "test['predictionglm']=logreg.predict(test[predictors])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
